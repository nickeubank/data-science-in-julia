
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Dask DataFrames &#8212; Practical Data Science</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Dask-DataFrames">
<h1>Dask DataFrames<a class="headerlink" href="#Dask-DataFrames" title="Permalink to this headline">¶</a></h1>
<p>(Note: This tutorial is a fork of the official dask tutorial, which you can <a class="reference external" href="https://github.com/dask/dask-tutorial">find here</a>)</p>
<p>In this tutorial, we will use <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code> to do parallel operations on dask dataframes look and feel like Pandas dataframes but they run on the same infrastructure that powers <code class="docutils literal notranslate"><span class="pre">dask.delayed</span></code>.</p>
<div class="section" id="Start-your-own-cluster!">
<h2>Start your own cluster!<a class="headerlink" href="#Start-your-own-cluster!" title="Permalink to this headline">¶</a></h2>
<p>dask has many backends, but the one that’s most versitile (and often most performant) is the <code class="docutils literal notranslate"><span class="pre">distributed</span></code> backend, so let’s use that here. Run:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">()</span>
</pre></div>
</div>
<p>to create a set of workers on your computer. This cluster is running only on your own computer, but it operates exactly the way it would work on a cloud cluster where these workers live on other computers.</p>
<p><strong>Note:</strong> these workers communication via networking protocols, so your firewall / anti-virus may ask if it’s ok to let Python accept connections (it is!). If you can’t get your system running, it may be due to your firewall / anti-virus. In that case, try <code class="docutils literal notranslate"><span class="pre">client</span> <span class="pre">=</span> <span class="pre">Client(processes=False)</span></code>. This will create four workers hiding in the same process (obviating the need for network protocols for communication).</p>
<div class="section" id="Real-Data">
<h3>Real Data<a class="headerlink" href="#Real-Data" title="Permalink to this headline">¶</a></h3>
<p>Lets try this with an extract of flights in the USA across several years. This data is specific to flights out of the three airports in the New York City area. To begin, download <a class="reference external" href="https://storage.googleapis.com/dask-tutorial-data/nycflights.tar.gz">NYC Flight data here</a>, and unzip it somewhere you can find it.</p>
<p><strong>(1)</strong> Look at the data in the folder. As you will see it is in many files. Unlike pandas, however, dask can load collections of files all at once. Run <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">dask.dataframe</span> <span class="pre">as</span> <span class="pre">dd</span></code>, then using <code class="docutils literal notranslate"><span class="pre">dd.read_csv</span></code> with an asterix wildcard to load all the files at once with something like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;/users/nick/downloads/nycflights/*.csv&#39;</span><span class="p">,</span>
                 <span class="n">parse_dates</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Date&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]})</span>
</pre></div>
</div>
<p>(The <code class="docutils literal notranslate"><span class="pre">parse_dates</span></code> option just tells dask that columns 1, 2, and 3 together form a date (they’re year, month, and day of the month respectively), and that dask should convert them to a single column called <code class="docutils literal notranslate"><span class="pre">Date</span></code> that is of type datetime. This isn’t special to dask, it’s just a pandas <code class="docutils literal notranslate"><span class="pre">read_csv</span></code> option.)</p>
<p><strong>(2)</strong> Look at your dataframe by just calling it (<code class="docutils literal notranslate"><span class="pre">df</span></code>). Notice that the respresentation of the dataframe object contains no data - Dask has just done enough to read the start of the first file, and infer the column names and types.</p>
<p><strong>(3)</strong> now use <code class="docutils literal notranslate"><span class="pre">df.head()</span></code> to ask dask to actually load a few rows.</p>
<p>We can view the start and end of the data</p>
<p><strong>(4)</strong> Now try and run <code class="docutils literal notranslate"><span class="pre">df.tail()</span></code>!</p>
</div>
<div class="section" id="What-just-happened?">
<h3>What just happened?<a class="headerlink" href="#What-just-happened?" title="Permalink to this headline">¶</a></h3>
<p>Unlike <code class="docutils literal notranslate"><span class="pre">pandas.read_csv</span></code> which reads in the entire file before inferring datatypes, <code class="docutils literal notranslate"><span class="pre">dask.dataframe.read_csv</span></code> only reads in a sample from the beginning of the file (or first file if using a glob). These inferred datatypes are then enforced when reading all partitions.</p>
<p>In this case, the datatypes inferred in the sample are incorrect. The first <code class="docutils literal notranslate"><span class="pre">n</span></code> rows have no value for <code class="docutils literal notranslate"><span class="pre">CRSElapsedTime</span></code> (which pandas infers as a <code class="docutils literal notranslate"><span class="pre">float</span></code>), and later on turn out to be strings (<code class="docutils literal notranslate"><span class="pre">object</span></code> dtype). Note that Dask gives an informative error message about the mismatch. When this happens you have a few options:</p>
<ul class="simple">
<li><p>Specify dtypes directly using the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> keyword. This is the recommended solution, as it’s the least error prone (better to be explicit than implicit) and also the most performant.</p></li>
<li><p>Increase the size of the <code class="docutils literal notranslate"><span class="pre">sample</span></code> keyword (in bytes)</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">assume_missing</span></code> to make <code class="docutils literal notranslate"><span class="pre">dask</span></code> assume that columns inferred to be <code class="docutils literal notranslate"><span class="pre">int</span></code> (which don’t allow missing values) are actually floats (which do allow missing values). In our particular case this doesn’t apply.</p></li>
</ul>
<p>In our case we’ll use the first option and directly specify the <code class="docutils literal notranslate"><span class="pre">dtypes</span></code> of the offending columns: set <code class="docutils literal notranslate"><span class="pre">TailNum</span></code> to <code class="docutils literal notranslate"><span class="pre">str</span></code>, <code class="docutils literal notranslate"><span class="pre">CRSElapsedTime</span></code> to <code class="docutils literal notranslate"><span class="pre">float</span></code> and <code class="docutils literal notranslate"><span class="pre">Cancelled</span></code> to <code class="docutils literal notranslate"><span class="pre">bool</span></code>.</p>
</div>
</div>
<div class="section" id="Computations-with-dask.dataframe">
<h2>Computations with <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code><a class="headerlink" href="#Computations-with-dask.dataframe" title="Permalink to this headline">¶</a></h2>
<p>Suppose we want to compute the maximum of the <code class="docutils literal notranslate"><span class="pre">DepDelay</span></code> (short for Departure Delays) column. With just pandas, we would loop over each file to find the individual maximums, then find the final maximum over all the individual maximums</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">maxes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">maxes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">DepDelay</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>

<span class="n">final_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">maxes</span><span class="p">)</span>
</pre></div>
</div>
<p>But this is a far cry from what we do with smaller pandas dataset, which is just</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">DepDelay</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
<p>To solve this, we can use <code class="docutils literal notranslate"><span class="pre">dask</span></code>! <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code> lets us write pandas-like code, that operates on larger than memory datasets in parallel. To get the maximium value of the column, we can run:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">time</span> df.DepDelay.max().compute()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 175 ms, sys: 24.3 ms, total: 199 ms
Wall time: 2.45 s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1435.0
</pre></div></div>
</div>
<p>This writes the delayed computation for us and then runs it.</p>
<p>Some things to note:</p>
<ol class="arabic simple">
<li><p>Dask uses lazy evaluation, which means it doesn’t actually do any work till we call <code class="docutils literal notranslate"><span class="pre">.compute()</span></code>. If you just ran <code class="docutils literal notranslate"><span class="pre">df.DepDelay.max()</span></code>, you’d just get back a placeholder:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">DepDelay</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

<span class="n">dd</span><span class="o">.</span><span class="n">Scalar</span><span class="o">&lt;</span><span class="n">series</span><span class="o">-...</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float64</span><span class="o">&gt;</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Dask will delete intermediate results (like the full pandas dataframe for each file) as soon as possible.</p>
<ul class="simple">
<li><p>This lets us handle datasets that are larger than memory</p></li>
<li><p>This means that repeated computations will have to load all of the data in each time (run the code above again, is it faster or slower than you would expect?)</p></li>
</ul>
</li>
</ol>
<p><strong>(5)</strong> Want to know more about what dask is doing? First, just store <code class="docutils literal notranslate"><span class="pre">df.DepDelay.max()</span></code> as a new variable and look at it. Can you see the placeholder? It tells you what it will eventually be (a scalar (single value) float64). But you don’t see the actual maximum value.</p>
<p><strong>(6)</strong> Now use <code class="docutils literal notranslate"><span class="pre">.visualize()</span></code> on that variable to see the <em>plan</em> dask has for getting you the maximimum value if you were to run your code right now.</p>
</div>
<div class="section" id="Let’s-do-some-manipulations!">
<h2>Let’s do some manipulations!<a class="headerlink" href="#Let’s-do-some-manipulations!" title="Permalink to this headline">¶</a></h2>
<p>In this section we do a few <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code> computations. If you are comfortable with Pandas then these should be familiar. You will have to think about when to call <code class="docutils literal notranslate"><span class="pre">compute</span></code>.</p>
<p><strong>(7)</strong> In total, what is the average delay (<code class="docutils literal notranslate"><span class="pre">DepDelay</span></code>) for non-canceled flights?</p>
<p><strong>(8)</strong> In total, how many non-cancelled flights were taken from each airport?</p>
<p><em>Hint</em>: use <code class="docutils literal notranslate"><span class="pre">df.groupby</span></code> and <code class="docutils literal notranslate"><span class="pre">size</span></code>.</p>
<p><strong>(9)</strong> What was the average departure delay from each airport? (<code class="docutils literal notranslate"><span class="pre">DepDelay</span></code>)</p>
<p><strong>(10)</strong> How many rows are in our dataset?</p>
<p>Note you’ve probably just found what I think is one of the trickiest things to figure out with a distributed computing system like dask: <em>some</em> functions don’t follow the rules of delayed evaluation, and when you run them, dask executes immediately. <code class="docutils literal notranslate"><span class="pre">len</span></code> is one of those functions.</p>
<p>As we’ll discuss below, a good rule of thumb is that anything that isn’t either (a) a method on the dask dataframe (i.e. something that isn’t of the form <code class="docutils literal notranslate"><span class="pre">df.METHOD()</span></code>), or an explicit dask function (something you call from the dask library, like <code class="docutils literal notranslate"><span class="pre">dd.to_parquet</span></code>), it will probably execute immediately.</p>
<p><code class="docutils literal notranslate"><span class="pre">len</span></code> is pretty safe since all it returns is a single number, so it’s unlikely to blow up your computer if it runs before you want, but you have to be careful with other functions, because if you were to us a pandas function like <code class="docutils literal notranslate"><span class="pre">pd.to_numeric(df)</span></code>, it will execute immediately, and it will do so by pulling all the data into your client session as a single giant dataframe, and with a larger dataset, it is likely to crash you computer when you do so.</p>
<p>An alternative that <em>won’t</em> execute until you run <code class="docutils literal notranslate"><span class="pre">compute</span></code> is <code class="docutils literal notranslate"><span class="pre">df.shape[0]</span></code> (see how it takes the form of a method on our dask dataframe <code class="docutils literal notranslate"><span class="pre">df</span></code>?) Try it to see!</p>
</div>
<div class="section" id="Sharing-Intermediate-Results">
<h2>Sharing Intermediate Results<a class="headerlink" href="#Sharing-Intermediate-Results" title="Permalink to this headline">¶</a></h2>
<p>When computing all of the above, we sometimes did the same operation more than once. For most operations, <code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code> hashes the arguments, allowing duplicate computations to be shared, and only computed once.</p>
<p>For example, lets compute the mean and standard deviation for departure delay of all non-canceled flights. Since dask operations are lazy, those values aren’t the final results yet. They’re just the recipe required to get the result.</p>
<p>If we compute them with two calls to compute, there is no sharing of intermediate computations.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">non_cancelled</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="o">.</span><span class="n">Cancelled</span><span class="p">]</span>
<span class="n">mean_delay</span> <span class="o">=</span> <span class="n">non_cancelled</span><span class="o">.</span><span class="n">DepDelay</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">std_delay</span> <span class="o">=</span> <span class="n">non_cancelled</span><span class="o">.</span><span class="n">DepDelay</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>

<span class="n">mean_delay_res</span> <span class="o">=</span> <span class="n">mean_delay</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">std_delay_res</span> <span class="o">=</span> <span class="n">std_delay</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 376 ms, sys: 43.4 ms, total: 419 ms
Wall time: 3.88 s
</pre></div></div>
</div>
<p>But lets try by passing both to a single <code class="docutils literal notranslate"><span class="pre">compute</span></code> call.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">dask</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>

<span class="n">mean_delay_res</span><span class="p">,</span> <span class="n">std_delay_res</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">mean_delay</span><span class="p">,</span> <span class="n">std_delay</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 237 ms, sys: 26.5 ms, total: 264 ms
Wall time: 2 s
</pre></div></div>
</div>
<p>Using <code class="docutils literal notranslate"><span class="pre">dask.compute</span></code> takes roughly 1/2 the time. This is because the task graphs for both results are merged when calling <code class="docutils literal notranslate"><span class="pre">dask.compute</span></code>, allowing shared operations to only be done once instead of twice. In particular, using <code class="docutils literal notranslate"><span class="pre">dask.compute</span></code> only does the following once:</p>
<ul class="simple">
<li><p>the calls to <code class="docutils literal notranslate"><span class="pre">read_csv</span></code></p></li>
<li><p>the filter (<code class="docutils literal notranslate"><span class="pre">df[~df.Cancelled]</span></code>)</p></li>
<li><p>some of the necessary reductions (<code class="docutils literal notranslate"><span class="pre">sum</span></code>, <code class="docutils literal notranslate"><span class="pre">count</span></code>)</p></li>
</ul>
<p>To see what the merged task graphs between multiple results look like (and what’s shared), you can use the <code class="docutils literal notranslate"><span class="pre">dask.visualize</span></code> function (we might want to use <code class="docutils literal notranslate"><span class="pre">filename='graph.pdf'</span></code> to zoom in on the graph better):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dask</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">mean_delay</span><span class="p">,</span> <span class="n">std_delay</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/exercises_Exercise_dask_25_0.png" src="../_images/exercises_Exercise_dask_25_0.png" />
</div>
</div>
<p>But lets try by passing both to a single <code class="docutils literal notranslate"><span class="pre">compute</span></code> call.</p>
<p><strong>(11)</strong> Now you try – for each airport, get both the average delay and the maximum delay in the data for flights that weren’t cancelled.</p>
<p>(As another example of places that distributed computing gets tricky, while it’s easy to do means and maxes, you can’t easily get the median of a group (e.g.<code class="docutils literal notranslate"><span class="pre">df.groupby('Origin)['DepDelay'].median()</span></code>) in a distributed manner. There are workarounds, but these are the kinds of “fragile” things that make distributed computing a bit of a pain).</p>
</div>
<div class="section" id="Converting-Scheduled-Departure-Time-(CRSDepTime)-to-a-timestamp">
<h2>Converting Scheduled Departure Time (<code class="docutils literal notranslate"><span class="pre">CRSDepTime</span></code>) to a timestamp<a class="headerlink" href="#Converting-Scheduled-Departure-Time-(CRSDepTime)-to-a-timestamp" title="Permalink to this headline">¶</a></h2>
<p>This dataset stores the scheduled departure times of flights in the format <code class="docutils literal notranslate"><span class="pre">HHMM</span></code>, which are read in as integers in <code class="docutils literal notranslate"><span class="pre">read_csv</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">crs_dep_time</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">CRSDepTime</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">crs_dep_time</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    1540
1    1540
2    1540
3    1540
4    1540
5    1540
6    1540
7    1540
8    1540
9    1540
Name: CRSDepTime, dtype: int64
</pre></div></div>
</div>
<p>To combine the data we have on flight dates with these departure times into a single column that includes all that information in a single <code class="docutils literal notranslate"><span class="pre">datetime</span></code> format, we have to convert the time of day into a Timedelta type, then add those Timedeltas to our Date column to get a single column that knows the date AND time of day of departures. (Implicitly, dates think of themselves as living at midnight, so adding a timedelta of 10 hours moves them to 10am).</p>
<p>To convert these to timestamps of scheduled departure time, we need to convert these integers into <code class="docutils literal notranslate"><span class="pre">pd.Timedelta</span></code> objects, and then combine them with the <code class="docutils literal notranslate"><span class="pre">Date</span></code> column.</p>
<p>In pandas we’d do this using the <code class="docutils literal notranslate"><span class="pre">pd.to_timedelta</span></code> function, and a bit of arithmetic:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Get the first 10 dates to complement our `crs_dep_time`</span>
<span class="n">date</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Date</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Get hours as an integer, convert to a timedelta</span>
<span class="n">hours</span> <span class="o">=</span> <span class="n">crs_dep_time</span> <span class="o">//</span> <span class="mi">100</span>
<span class="n">hours_timedelta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_timedelta</span><span class="p">(</span><span class="n">hours</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">)</span>

<span class="c1"># Get minutes as an integer, convert to a timedelta</span>
<span class="n">minutes</span> <span class="o">=</span> <span class="n">crs_dep_time</span> <span class="o">%</span> <span class="mi">100</span>
<span class="n">minutes_timedelta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>

<span class="c1"># Apply the timedeltas to offset the dates by the departure time</span>
<span class="n">departure_timestamp</span> <span class="o">=</span> <span class="n">date</span> <span class="o">+</span> <span class="n">hours_timedelta</span> <span class="o">+</span> <span class="n">minutes_timedelta</span>
<span class="n">departure_timestamp</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0   1990-01-01 15:40:00
1   1990-01-02 15:40:00
2   1990-01-03 15:40:00
3   1990-01-04 15:40:00
4   1990-01-05 15:40:00
5   1990-01-06 15:40:00
6   1990-01-07 15:40:00
7   1990-01-08 15:40:00
8   1990-01-09 15:40:00
9   1990-01-10 15:40:00
dtype: datetime64[ns]
</pre></div></div>
</div>
<div class="section" id="Custom-code-and-Dask-Dataframe">
<h3>Custom code and Dask Dataframe<a class="headerlink" href="#Custom-code-and-Dask-Dataframe" title="Permalink to this headline">¶</a></h3>
<p>Notice that we never had to call <code class="docutils literal notranslate"><span class="pre">.compute()</span></code>! That’s because when we call a non-dask function on a dask dataframe, dask doesn’t know how to do it in parallel, so it brings in the whole dataframe and then passes it to your non-dask function. We can get away with that here because our data is small, but with a big dataset, your computer would crash!</p>
<p>Now we could swap out <code class="docutils literal notranslate"><span class="pre">pd.to_timedelta</span></code> for <code class="docutils literal notranslate"><span class="pre">dd.to_timedelta</span></code> (the dask implementation of <code class="docutils literal notranslate"><span class="pre">to_timedelta</span></code>), and we’d be fine. But let’s say that Dask hadn’t implemented a <code class="docutils literal notranslate"><span class="pre">dd.to_timedelta</span></code> that works on Dask DataFrames. What would you do then?</p>
<p><code class="docutils literal notranslate"><span class="pre">dask.dataframe</span></code> provides a few methods to make applying custom functions to Dask DataFrames easier:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://dask.pydata.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.map_partitions">map_partitions</a>: Apply function to each chunk.</p></li>
<li><p><a class="reference external" href="http://dask.pydata.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.map_overlap">map_overlap</a>: Allows you to apply to each chunk AND roll over a few rows (for things like rolling averages)</p></li>
<li><p><a class="reference external" href="http://dask.pydata.org/en/latest/dataframe-api.html#dask.dataframe.DataFrame.reduction">reduction</a>: Allows you to write a full, custom reduction function (where you specify how you’d reduce each chunk, then how you’d re-combine those reduced chunks).</p></li>
</ul>
<p>Of these, <code class="docutils literal notranslate"><span class="pre">map_partition</span></code> is the easiest. It says “just apply this function to each chunk”. Any operation that operates on each row individually can work with <code class="docutils literal notranslate"><span class="pre">map_partition</span></code>!</p>
<p>The basic idea is to apply a function that operates on a DataFrame to each partition. In this case, we’ll apply <code class="docutils literal notranslate"><span class="pre">pd.to_timedelta</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">hours</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">CRSDepTime</span> <span class="o">//</span> <span class="mi">100</span>
<span class="c1"># hours_timedelta = pd.to_timedelta(hours, unit=&#39;h&#39;)</span>
<span class="n">hours_timedelta</span> <span class="o">=</span> <span class="n">hours</span><span class="o">.</span><span class="n">map_partitions</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_timedelta</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">)</span>

<span class="n">minutes</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">CRSDepTime</span> <span class="o">%</span> <span class="mi">100</span>
<span class="c1"># minutes_timedelta = pd.to_timedelta(minutes, unit=&#39;m&#39;)</span>
<span class="n">minutes_timedelta</span> <span class="o">=</span> <span class="n">minutes</span><span class="o">.</span><span class="n">map_partitions</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_timedelta</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>

<span class="n">departure_timestamp</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">Date</span> <span class="o">+</span> <span class="n">hours_timedelta</span> <span class="o">+</span> <span class="n">minutes_timedelta</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">departure_timestamp</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Dask Series Structure:
npartitions=10
    datetime64[ns]
               ...
         ...
               ...
               ...
dtype: datetime64[ns]
Dask Name: add, 110 tasks
</pre></div></div>
</div>
<p>And you’ll see <em>this</em> time not everything ran all at once!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">departure_timestamp</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0   1990-01-01 15:40:00
1   1990-01-02 15:40:00
2   1990-01-03 15:40:00
3   1990-01-04 15:40:00
4   1990-01-05 15:40:00
dtype: datetime64[ns]
</pre></div></div>
</div>
<p><strong>(11)</strong> Rewrite what I did above to use a single call to <code class="docutils literal notranslate"><span class="pre">map_partitions</span></code> so that everything is done at once.</p>
<p>This will be slightly more efficient than two separate calls, as it reduces the number of tasks in the graph.</p>
<p>Do so by writing a single function that accomplishes what you want:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_departure_timestamp</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
     <span class="c1"># Do conversions here</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Limitations">
<h2>Limitations<a class="headerlink" href="#Limitations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="What-doesn’t-work?">
<h3>What doesn’t work?<a class="headerlink" href="#What-doesn’t-work?" title="Permalink to this headline">¶</a></h3>
<p>Dask.dataframe only covers a small but well-used portion of the Pandas API. This limitation is for two reasons:</p>
<ol class="arabic simple">
<li><p>The Pandas API is <em>huge</em></p></li>
<li><p>Some operations are genuinely hard to do in parallel (e.g. sort)</p></li>
</ol>
<p>Additionally, some important operations like <code class="docutils literal notranslate"><span class="pre">set_index</span></code> work, but are slower than in Pandas because they include substantial shuffling of data, and may write out to disk.</p>
</div>
<div class="section" id="What-definitely-works?">
<h3>What definitely works?<a class="headerlink" href="#What-definitely-works?" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Trivially parallelizable operations (fast):</p>
<ul>
<li><p>Elementwise operations: <code class="docutils literal notranslate"><span class="pre">df.x</span> <span class="pre">+</span> <span class="pre">df.y</span></code></p></li>
<li><p>Row-wise selections: <code class="docutils literal notranslate"><span class="pre">df[df.x</span> <span class="pre">&gt;</span> <span class="pre">0]</span></code></p></li>
<li><p>Loc: <code class="docutils literal notranslate"><span class="pre">df.loc[4.0:10.5]</span></code></p></li>
<li><p>Common aggregations: <code class="docutils literal notranslate"><span class="pre">df.x.max()</span></code></p></li>
<li><p>Is in: <code class="docutils literal notranslate"><span class="pre">df[df.x.isin([1,</span> <span class="pre">2,</span> <span class="pre">3])]</span></code></p></li>
<li><p>Datetime/string accessors: <code class="docutils literal notranslate"><span class="pre">df.timestamp.month</span></code></p></li>
</ul>
</li>
<li><p>Cleverly parallelizable operations (also fast):</p>
<ul>
<li><p>groupby-aggregate (with common aggregations): <code class="docutils literal notranslate"><span class="pre">df.groupby(df.x).y.max()</span></code></p></li>
<li><p>value_counts: <code class="docutils literal notranslate"><span class="pre">df.x.value_counts</span></code></p></li>
<li><p>Drop duplicates: <code class="docutils literal notranslate"><span class="pre">df.x.drop_duplicates()</span></code></p></li>
<li><p>Join on index: <code class="docutils literal notranslate"><span class="pre">dd.merge(df1,</span> <span class="pre">df2,</span> <span class="pre">left_index=True,</span> <span class="pre">right_index=True)</span></code></p></li>
</ul>
</li>
<li><p>Operations requiring a shuffle (slow-ish, unless on index)</p>
<ul>
<li><p>Set index: <code class="docutils literal notranslate"><span class="pre">df.set_index(df.x)</span></code></p></li>
<li><p>groupby-apply (with anything): <code class="docutils literal notranslate"><span class="pre">df.groupby(df.x).apply(myfunc)</span></code></p></li>
<li><p>Join not on the index: <code class="docutils literal notranslate"><span class="pre">pd.merge(df1,</span> <span class="pre">df2,</span> <span class="pre">on='name')</span></code></p></li>
</ul>
</li>
<li><p>Ingest operations</p>
<ul>
<li><p>Files: <code class="docutils literal notranslate"><span class="pre">dd.read_csv,</span> <span class="pre">dd.read_parquet,</span> <span class="pre">dd.read_json,</span> <span class="pre">dd.read_orc</span></code>, etc.</p></li>
<li><p>Pandas: <code class="docutils literal notranslate"><span class="pre">dd.from_pandas</span></code></p></li>
<li><p>Anything supporting numpy slicing: <code class="docutils literal notranslate"><span class="pre">dd.from_array</span></code></p></li>
<li><p>From any set of functions creating sub dataframes via <code class="docutils literal notranslate"><span class="pre">dd.from_delayed</span></code>.</p></li>
<li><p>Dask.bag: <code class="docutils literal notranslate"><span class="pre">mybag.to_dataframe(columns=[...])</span></code></p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="Want-more-practice?">
<h2>Want more practice?<a class="headerlink" href="#Want-more-practice?" title="Permalink to this headline">¶</a></h2>
<p>Let’s work with a REAL big dataset! Find your copy of the <code class="docutils literal notranslate"><span class="pre">ARCOS</span></code> DEA drug shipment database, and find the pharmaceutical company that has shipped the most pills (<code class="docutils literal notranslate"><span class="pre">DOSAGE_UNIT</span></code>) in the US.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Practical DS</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../class_schedule.html">CLASS SCHEDULE</a></li>
</ul>
<p class="caption"><span class="caption-text">PYTHON &amp; PANDAS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../setup_environment.html">Setting Up Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../managing_python_packages.html">Managing Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python_v_r.html">Python / R Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vars_v_objects.html">Python: Vars v Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ints_and_floats.html">Numbers in Computers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas_series.html">Pandas 1: Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pandas_dataframes.html">Pandas 2: DataFrames</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plotting_part1.html">Plotting, Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plotting_part2.html">Plotting, Advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="../views_and_copies_in_pandas.html">Pandas 3: Views</a></li>
</ul>
<p class="caption"><span class="caption-text">OTHER TOOLS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../command_line_part1.html">Command Line, Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../command_line_part2.html">Command Line, Advanced</a></li>
<li class="toctree-l1"><a class="reference internal" href="../jupyter.html">Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../git_and_github.html">Git and Github</a></li>
</ul>
<p class="caption"><span class="caption-text">SKILLS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_help.html">Getting Help Online</a></li>
<li class="toctree-l1"><a class="reference internal" href="../defensive_programming.html">Defensive Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../workflow.html">Workflow Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../what_is_big_data.html">What is Big Data?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../big_data_strategies.html">Working with Big Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_understanding.html">Understanding Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance_solutions.html">Solving Performance Probs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelism.html">Parallel Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_computing.html">Distributed Computing</a></li>
</ul>
<p class="caption"><span class="caption-text">OTHER</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../not_a_mids_student.html">Not a MIDS Student?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cheatsheets.html">Cheat Sheets</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Nick Eubank.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/exercises/Exercise_dask.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-133829453-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>